"""
Whisper ASR integration for automatic lyrics generation.
"""
from pathlib import Path
from typing import Optional, Dict, List, Tuple
import logging

# Try to import whisper dependencies
try:
    import whisper
    import torch
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

# Try to import for VAD (Voice Activity Detection)
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

from lyricflow.utils.logging import get_logger
from lyricflow.utils.config import WhisperConfig

logger = get_logger(__name__)


class WhisperLyricGenerator:
    """Generate time-synced lyrics from audio using Whisper ASR."""
    
    def __init__(self, config: Optional[WhisperConfig] = None):
        """
        Initialize Whisper lyric generator.
        
        Args:
            config: Whisper configuration
        """
        if not WHISPER_AVAILABLE:
            raise ImportError(
                "Whisper support requires: pip install openai-whisper torch"
            )
        
        self.config = config or WhisperConfig()
        self.model = None
        self.device = self._get_device()
        
        logger.info(f"Whisper generator initialized with device: {self.device}")
    
    def _get_device(self) -> str:
        """
        Get the device to use for inference.
        
        Returns:
            Device string ('cuda' or 'cpu')
        """
        if self.config.device == "cuda" and torch.cuda.is_available():
            return "cuda"
        return "cpu"
    
    def load_model(self):
        """Load the Whisper model."""
        if self.model is None:
            logger.info(f"Loading Whisper model: {self.config.model_size}")
            self.model = whisper.load_model(
                self.config.model_size,
                device=self.device
            )
            logger.info("Whisper model loaded successfully")
    
    def transcribe_audio(
        self,
        audio_path: Path,
        language: str = "ja",
        task: str = "transcribe"
    ) -> Dict:
        """
        Transcribe audio file with timestamps.
        
        Args:
            audio_path: Path to audio file
            language: Source language code (e.g., 'ja', 'en')
            task: 'transcribe' or 'translate'
            
        Returns:
            Dictionary with transcription results including segments
        """
        if not audio_path.exists():
            raise FileNotFoundError(f"Audio file not found: {audio_path}")
        
        self.load_model()
        
        logger.info(f"Transcribing audio: {audio_path.name}")
        
        # Transcribe with word-level timestamps
        result = self.model.transcribe(
            str(audio_path),
            language=language,
            task=task,
            word_timestamps=True,
            verbose=False
        )
        
        logger.info(f"Transcription complete: {len(result.get('segments', []))} segments")
        
        return result
    
    def generate_lrc(
        self,
        audio_path: Path,
        language: str = "ja",
        output_path: Optional[Path] = None
    ) -> str:
        """
        Generate LRC format lyrics from audio.
        
        Args:
            audio_path: Path to audio file
            language: Source language code
            output_path: Optional path to save LRC file
            
        Returns:
            LRC formatted string
        """
        result = self.transcribe_audio(audio_path, language)
        
        lrc_lines = []
        
        # Add metadata
        lrc_lines.append("[ti:Generated by LyricFlow]")
        lrc_lines.append("[ar:Unknown Artist]")
        lrc_lines.append("[al:Unknown Album]")
        lrc_lines.append("[by:Whisper ASR]")
        lrc_lines.append("")
        
        # Process segments
        for segment in result.get("segments", []):
            timestamp = self._format_timestamp(segment["start"])
            text = segment["text"].strip()
            lrc_lines.append(f"[{timestamp}]{text}")
        
        lrc_content = "\n".join(lrc_lines)
        
        # Save if output path provided
        if output_path:
            output_path.write_text(lrc_content, encoding="utf-8")
            logger.info(f"LRC file saved: {output_path}")
        
        return lrc_content
    
    def generate_word_level_lrc(
        self,
        audio_path: Path,
        language: str = "ja",
        output_path: Optional[Path] = None
    ) -> str:
        """
        Generate word-level LRC format lyrics from audio.
        
        Args:
            audio_path: Path to audio file
            language: Source language code
            output_path: Optional path to save LRC file
            
        Returns:
            Word-level LRC formatted string
        """
        result = self.transcribe_audio(audio_path, language)
        
        lrc_lines = []
        
        # Add metadata
        lrc_lines.append("[ti:Generated by LyricFlow - Word Level]")
        lrc_lines.append("[ar:Unknown Artist]")
        lrc_lines.append("[al:Unknown Album]")
        lrc_lines.append("[by:Whisper ASR]")
        lrc_lines.append("")
        
        # Process segments with word timestamps
        for segment in result.get("segments", []):
            words = segment.get("words", [])
            
            if words:
                # Create line with word-level timestamps
                for word in words:
                    timestamp = self._format_timestamp(word["start"])
                    text = word["word"].strip()
                    lrc_lines.append(f"[{timestamp}]{text}")
            else:
                # Fallback to segment level
                timestamp = self._format_timestamp(segment["start"])
                text = segment["text"].strip()
                lrc_lines.append(f"[{timestamp}]{text}")
        
        lrc_content = "\n".join(lrc_lines)
        
        # Save if output path provided
        if output_path:
            output_path.write_text(lrc_content, encoding="utf-8")
            logger.info(f"Word-level LRC file saved: {output_path}")
        
        return lrc_content
    
    @staticmethod
    def _format_timestamp(seconds: float) -> str:
        """
        Format timestamp for LRC file.
        
        Args:
            seconds: Time in seconds
            
        Returns:
            Formatted timestamp string (mm:ss.xx)
        """
        minutes = int(seconds // 60)
        seconds = seconds % 60
        return f"{minutes:02d}:{seconds:05.2f}"
    
    def apply_vad(self, audio_path: Path) -> List[Tuple[float, float]]:
        """
        Apply Voice Activity Detection to find speech segments.
        
        Args:
            audio_path: Path to audio file
            
        Returns:
            List of (start, end) tuples for speech segments
        """
        if not self.config.use_vad:
            return []
        
        if not NUMPY_AVAILABLE:
            logger.warning("VAD requires numpy, skipping")
            return []
        
        # Placeholder for VAD implementation
        # Could use webrtcvad, silero-vad, or Whisper's built-in VAD
        logger.info("VAD processing not yet implemented")
        return []
    
    def estimate_progress(self, audio_path: Path) -> float:
        """
        Estimate transcription progress.
        
        Args:
            audio_path: Path to audio file
            
        Returns:
            Estimated duration in seconds
        """
        # Placeholder - would need audio duration calculation
        return 0.0


def generate_lyrics_from_audio(
    audio_path: Path,
    output_path: Optional[Path] = None,
    language: str = "ja",
    model_size: str = "medium",
    device: str = "cpu",
    word_level: bool = False
) -> str:
    """
    Convenience function to generate lyrics from audio.
    
    Args:
        audio_path: Path to audio file
        output_path: Optional path to save LRC file
        language: Source language code
        model_size: Whisper model size (tiny, base, small, medium, large)
        device: Device to use (cpu or cuda)
        word_level: Generate word-level timestamps
        
    Returns:
        LRC formatted lyrics
    """
    config = WhisperConfig(
        model_size=model_size,
        device=device,
        use_vad=True
    )
    
    generator = WhisperLyricGenerator(config)
    
    if word_level:
        return generator.generate_word_level_lrc(audio_path, language, output_path)
    else:
        return generator.generate_lrc(audio_path, language, output_path)
